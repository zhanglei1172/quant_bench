calibration:
  dataset_id: /dataset/workspace/lim42/datasets/ultra_chat_200k/
  dataset_split: train_sft
  num_samples: 512
  max_sequence_length: 2048

quant_modifiers:
  SpinQuantModifier:
    rotations: ["R4"]
    transform_block_size_R4: 256
    transform_type: "hadamard"
  GPTQModifier:
    actorder: null
    ignore: ["lm_head", "re:visual.*", "re:model.visual.*"]
    config_groups:
      group_0:
        weights:
          num_bits: 4
          type: int
          symmetric: true
          strategy: channel
          observer: mse
        input_activations:
          num_bits: 8
          type: int
          symmetric: true
          strategy: tensor
          dynamic: false
        targets: [Linear]
      group_1:
        weights:
          num_bits: 4
          type: int
          symmetric: true
          strategy: channel
          observer: mse
        # input_activations: null
        # special outliers handling for down_proj layers activation quantization of Qwen3-8B model
        targets: ["re:model.layers.6.mlp.down_proj", "re:model.layers.16.mlp.down_proj"]

save_compressed: true
dtype: float32