name: gptq-w8a8-static-ignore-down

output_suffix: -R4-gptq-W8A8-static-ignore-down

calibration:
  dataset_id: /dataset/workspace/lim42/datasets/ultra_chat_200k/
  dataset_split: train_sft
  num_samples: 512
  max_sequence_length: 2048

quant_modifiers:
  SpinQuantModifier:
    rotations: ["R4"]
    transform_block_size: 256
    transform_type: "hadamard"
  GPTQModifier:
    actorder: null
    ignore: ["lm_head", "re:visual.*", "re:model.visual.*", "re:.*down_proj$"]
    config_groups:
      group_0:
        weights: {num_bits: 8, type: int, symmetric: true, strategy: channel}
        input_activations: {num_bits: 8, type: int, symmetric: true, strategy: tensor, dynamic: false}
        targets: [Linear]

save_compressed: true